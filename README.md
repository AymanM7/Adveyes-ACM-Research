

![Screenshot_25-11-2025_22249_github com](https://github.com/user-attachments/assets/eaec2ef0-7c22-4fc5-9d02-0224600fb150)






# ADVEYES


## Overview
ADVEYES is a research prototype exploring a faster, more accessible way to capture **objective attention signals** using common hardware (laptop webcam + mic) for thoose with instable medical insurance or thoose who have limited financial resources. Traditional ADHD evaluation often relies heavily on self-report and long clinical assesment; our goal is to pair a short task battery with measurable behavioral and speech markers to support research-grade screening signals.

## Experiment Process / Setup
We created a simple scheduling pipeline to run participants in our lab:
- **Google Form** for participants to fill out and ** give consent to participate in our study**
- **Calendly** for scheduling sessions
- **Participants:** **10 clinically diagnosed ADHD** + **10 non-ADHD** controls

During lab sessions we collected:
- **Eye tracking** (only during Card CPT)
- **Audio recordings** (during Stroop, Free Speech, and Math/Number Sense)
- **Task performance data** (accuracy, timing, and other key derived metrics specific to each test)

---

## Tasks

### Card CPT (Eye Tracking + Performance)
A sustained-attention task where participants respond to target stimuli across repeated trials.

**Captured data:**
- Webcam-based eye tracking session data
- Task performance (responses + timing)

> This is the **only** task that runs with live eye tracking gaze sessions.



![Screenshot_23-12-2025_134513_localhost](https://github.com/user-attachments/assets/2015f09b-5666-463f-9884-97b2c7e9eb2c)


![Screenshot_23-12-2025_134612_localhost](https://github.com/user-attachments/assets/649967ba-fb88-42de-aa14-6013e292af21)




<img width="1527" height="855" alt="Screenshot 2025-12-18 015015" src="https://github.com/user-attachments/assets/a1945999-37c6-44e3-92c1-6068972ddfab" />






---

### Stroop CPT (Audio + Key Cognitive Metrics)
A selective attention / inhibition task with 69 questions taking on  congruent vs incongruent interference.

**Captured data (most important):**
- **Accuracy %** (total number of questions correct)
- **Reaction Time (RT)** = *speech onset − stimulus onset* (ms)
- **RT Interference** = *Mean RT(Incongruent) − Mean RT(Baseline)*
- **Hesitation / Disfluency Count** (speech disruption, strongest in incongruent trials)


![Screenshot_23-12-2025_134733_localhost](https://github.com/user-attachments/assets/aecb0831-b33c-4ffc-9d27-0beaf09725e4)



![Screenshot_23-12-2025_13499_localhost](https://github.com/user-attachments/assets/41efbf95-d4bb-46a9-8590-651fadd53137)




---

### Free Speech Test (Audio)
Participants speak to a prompt for a fixed time window on a nuetral topic.

**Captured data:**
- audio recording for speech feature extraction (pacing, pauses, variability, etc.)



![Screenshot_23-12-2025_134947_localhost](https://github.com/user-attachments/assets/6b51d6d9-9de5-4cb3-9453-7a12ba1df34e)



---

### Math and Number Sense Test (Audio + Performance)
Participants solve number-sense / reasoning questions and explain answers out loud while working through the math questions.

**Captured data:**
- Harmonics To Noise Ratio
- Jitter
- RT
- Pitch/Intensity


![Screenshot_23-12-2025_13504_localhost](https://github.com/user-attachments/assets/edb5d829-b72c-455a-9e58-c7833184fd0b)


![Screenshot_23-12-2025_135012_localhost](https://github.com/user-attachments/assets/a955c85d-af4a-41e8-a085-8b40a5510ae0)





